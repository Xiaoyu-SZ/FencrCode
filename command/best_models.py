'python main.py --model_name BiasedMF --val_metrics ndcg@10 --test_metrics ndcg@5.10.20.50.100,hit@10,recall@10.20,precision@10 --lr 0.001 --es_patience 20 --eval_batch_size 8 --batch_size 256 --dataset recsys2017-1-1 --l2 1e-07 --vec_size 64 --test_sample_n 1000 --val_sample_n 1000'
'python main.py --model_name BiasedMF --val_metrics ndcg@10 --test_metrics ndcg@5.10.20.50.100,hit@10,recall@10.20,precision@10 --lr 0.001 --es_patience 20 --eval_batch_size 8 --batch_size 256 --dataset taobao-1-1 --l2 1e-07 --vec_size 64 --test_sample_n 1000 --val_sample_n 1000'
'python main.py --model_name FM --val_metrics ndcg@10 --test_metrics ndcg@5.10.20.50.100,hit@10,recall@10.20,precision@10 --lr 0.001 --es_patience 20 --eval_batch_size 8 --batch_size 256 --dataset recsys2017-1-1 --l2 0 --vec_size 64 --test_sample_n 1000 --val_sample_n 1000'
'python main.py --model_name FM --val_metrics ndcg@10 --test_metrics ndcg@5.10.20.50.100,hit@10,recall@10.20,precision@10 --lr 0.0001 --es_patience 20 --eval_batch_size 8 --batch_size 64 --dataset taobao-1-1 --l2 0.0001 --vec_size 8 --test_sample_n 1000 --val_sample_n 1000'
'python main.py --model_name WideDeep --val_metrics ndcg@10 --test_metrics ndcg@5.10.20.50.100,hit@10,recall@10.20,precision@10 --dropout 0.0 --lr 0.0001 --es_patience 20 --eval_batch_size 8 --batch_size 256 --dataset recsys2017-1-1 --l2 1e-07 --vec_size 64 --test_sample_n 1000 --val_sample_n 1000'
'python main.py --model_name WideDeep --val_metrics ndcg@10 --test_metrics ndcg@5.10.20.50.100,hit@10,recall@10.20,precision@10 --l2 0 --loss_sum 1 --dataset taobao-1-1 --es_patience 20 --eval_batch_size 8 --batch_size 128 --test_sample_n 1000 --val_sample_n 1000'
'python main.py --model_name DeepFM --val_metrics ndcg@10 --test_metrics ndcg@5.10.20.50.100,hit@10,recall@10.20,precision@10 --dropout 0.2 --lr 0.0001 --es_patience 20 --eval_batch_size 8 --batch_size 64 --dataset recsys2017-1-1 --l2 0 --vec_size 32 --test_sample_n 1000 --val_sample_n 1000'
'python main.py --model_name DeepFM --val_metrics ndcg@10 --test_metrics ndcg@5.10.20.50.100,hit@10,recall@10.20,precision@10 --dropout 0 --lr 0.001 --es_patience 20 --eval_batch_size 8 --batch_size 256 --dataset taobao-1-1 --l2 0 --vec_size 4 --test_sample_n 1000 --val_sample_n 1000'
'python main.py --model_name AFM --val_metrics ndcg@10 --test_metrics ndcg@5.10.20.50.100,hit@10,recall@10.20,precision@10 --l2 0 --es_patience 20 --eval_batch_size 8 --batch_size 128 --dataset recsys2017-1-1 --test_sample_n 1000 --val_sample_n 1000'
'python main.py --model_name AFM --val_metrics ndcg@10 --test_metrics ndcg@5.10.20.50.100,hit@10,recall@10.20,precision@10 --l2 0 --es_patience 20 --eval_batch_size 8 --batch_size 128 --dataset taobao-1-1 --test_sample_n 1000 --val_sample_n 1000'
'python main.py --model_name XGBoost --val_metrics ndcg@10 --test_metrics ndcg@5.10.20,hit@10,recall@10.20,precision@10 --es_patience 20 --test_sample_n 1000 --val_sample_n 1000 --dataset recsys2017-1-1 --l2 10 --lr 0.5 --max_depth 14'
'python main.py --model_name XGBoost --val_metrics ndcg@10 --test_metrics ndcg@5.10.20,hit@10,recall@10.20,precision@10 --es_patience 20 --test_sample_n 1000 --val_sample_n 1000 --dataset taobao-1-1 --l2 1 --lr 0.01 --max_depth 36'
'python main.py --model_name BiasedMF --val_metrics ndcg@10 --test_metrics ndcg@5.10.20.50.100,hit@10,recall@10.20,precision@10 --lr 0.0001 --es_patience 20 --eval_batch_size 8 --batch_size 128 --dataset recsys2017-1-1 --l2 1e-06 --loss_type mse --vec_size 32 --test_sample_n 1000 --val_sample_n 1000'
'python main.py --model_name BiasedMF --val_metrics ndcg@10 --test_metrics ndcg@5.10.20.50.100,hit@10,recall@10.20,precision@10 --lr 0.0001 --es_patience 20 --eval_batch_size 8 --batch_size 256 --dataset taobao-1-1 --l2 1e-05 --loss_type mse --vec_size 16 --test_sample_n 1000 --val_sample_n 1000'
'python main.py --model_name LTNRec --val_metrics ndcg@10 --test_metrics ndcg@5.10.20.50.100,hit@10,recall@10.20,precision@10 --es_patience 20 --eval_batch_size 8 --test_sample_n 1000 --val_sample_n 1000 --modeltype ltn --lr 0.001 --batch_size 256 --dataset recsys2017-1-1 --l2 0 --vec_size 64'
'python main.py --model_name LTNRec --val_metrics ndcg@10 --test_metrics ndcg@5.10.20.50.100,hit@10,recall@10.20,precision@10 --es_patience 20 --eval_batch_size 8 --test_sample_n 1000 --val_sample_n 1000 --modeltype ltn --lr 0.0001 --batch_size 256 --dataset taobao-1-1 --l2 1e-07 --vec_size 64'
'python main.py --model_name LINNRec --val_metrics ndcg@10 --test_metrics ndcg@5.10.20.50.100,hit@10,recall@10.20,precision@10 --max_his 20 --lr 0.0001 --es_patience 20 --eval_batch_size 8 --batch_size 128 --dataset recsys2017-1-1 --r_logic 1e-08 --l2 0.0001 --vec_size 64 --test_sample_n 1000 --val_sample_n 1000'
'python main.py --model_name LINNRec --val_metrics ndcg@10 --test_metrics ndcg@5.10.20.50.100,hit@10,recall@10.20,precision@10 --max_his 5 --seq_rec 1 --dataset taobao-1-1 --l2 1e-06 --lr 0.001 --loss_sum 1 --es_patience 20 --eval_batch_size 8 --batch_size 128 --r_logic 1e-07 --test_sample_n 1000 --val_sample_n 1000'
'python main.py --model_name NCR --val_metrics ndcg@10 --test_metrics ndcg@5.10.20.50.100,hit@10,recall@10.20,precision@10 --max_his 5 --dataset recsys2017-1-1 --l2 0 --lr 0.001 --loss_sum 1 --es_patience 20 --eval_batch_size 8 --batch_size 128 --r_logic 1e-05 --test_sample_n 1000 --val_sample_n 1000'
'python main.py --model_name NCR --val_metrics ndcg@10 --test_metrics ndcg@5.10.20.50.100,hit@10,recall@10.20,precision@10 --max_his 20 --lr 0.001 --es_patience 20 --eval_batch_size 8 --batch_size 256 --dataset taobao-1-1 --r_logic 0.0001 --l2 0.0001 --vec_size 32 --test_sample_n 1000 --val_sample_n 1000'
'python main.py --model_name NSICF --val_metrics ndcg@10 --test_metrics ndcg@5.10.20,hit@10,recall@10.20,precision@10 --eval_batch_size 8 --es_patience 20 --loss_sum 1 --batch_size 128 --test_sample_n 1000 --val_sample_n 1000 --top_structure 32 --lr 0.01 --use_sch --dataset recsys2017-1-1 --l2 1e-08 --structure 10@32'
'python main.py --model_name NSICF --val_metrics ndcg@10 --test_metrics ndcg@5.10.20,hit@10,recall@10.20,precision@10 --eval_batch_size 8 --es_patience 20 --loss_sum 1 --batch_size 128 --test_sample_n 1000 --val_sample_n 1000 --top_structure 32 --lr 0.005 --use_sch --dataset taobao-1-1 --l2 1e-08 --structure 10@32'

'python main.py --model_name FENCR --val_metrics ndcg@10 --test_metrics ndcg@5.10.20,hit@10,recall@10.20,precision@10 --eval_batch_size 8 --latent_dim 1 --bucket_size 0 --dataset taobao-1-1 --l2 1e-06 --lr 0.001 --es_patience 20 --output_strategy adaptive_sigmoid_ui --r_logic 1e-06 --loss_sum 1 --adaptive_loss 1 --layers [16] --batch_size 128 --test_sample_n 1000 --val_sample_n 1000'
'python main.py --model_name FENCR --val_metrics ndcg@10 --test_metrics ndcg@5.10.20,hit@10,recall@10.20,precision@10 --eval_batch_size 8 --latent_dim 1 --bucket_size 0 --dataset recsys2017-1-1 --l2 1e-06 --lr 0.001 --es_patience 20 --output_strategy adaptive_sigmoid_ui --loss_sum 1 --adaptive_loss 1 --layers [16] --batch_size 128 --test_sample_n 1000 --val_sample_n 1000 --r_logic 1e-08 --random_seed 1949'





